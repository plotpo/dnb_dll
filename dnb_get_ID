#falls name + titel: id setzen

import requests
from bs4 import BeautifulSoup as soup
import unicodedata
from lxml import etree
import pandas as pd
import csv

#Die Funktion dnb_sru nimmt den Parameter "query" der SRU-Abfrage 
#entgegen und liefert alle Ergebnisse als eine Liste von Records 
#aus. Bei mehr als 100 Records werden weitere Datensätze mit 
#"&startRecord=101" abgerufen (mögliche Werte 1 bis 99.000). 
def dnb_sru(query):
    
    base_url = "https://services.dnb.de/sru/dnb"
    params = {'recordSchema' : 'MARC21-xml',
          'operation': 'searchRetrieve',
          'version': '1.1',
          'maximumRecords': '100',
          'query': query
         }
    r = requests.get(base_url, params=params)
    xml = soup(r.content)
    records = xml.find_all('record', {'type':'Bibliographic'})
    
    if len(records) < 100:
        
        return records
    
    else:
        
        num_results = 100
        i = 101
        while num_results == 100:
            
            params.update({'startRecord': i})
            r = requests.get(base_url, params=params)
            xml = soup(r.content)
            new_records = xml.find_all('record', {'type':'Bibliographic'})
            records+=new_records
            i+=100
            num_results = len(new_records)
            
        return records
    

#Die Funktion parse_records nimmt als Parameter jeweils ein 
#Record entgegen und sucht über xpath die gewünschte 
#Informationen heraus und liefert diese als Dictionary zurück. 
def parse_record(record):
    
    ns = {"marc":"http://www.loc.gov/MARC21/slim"}
    xml = etree.fromstring(unicodedata.normalize("NFC", str(record)))
         
    #author
    author = xml.xpath("marc:datafield[@tag = '100']/marc:subfield[@code = 'a']", namespaces=ns)
    try:
        author = author[0].text
    except:
        author = "unknown"
    
    #titel
    titel = xml.xpath("marc:datafield[@tag = '245']/marc:subfield[@code = 'a']", namespaces=ns)
    try:
        titel = titel[0].text
    except:
        titel = "unknown"
           
    #GND-Nummer
    GND = xml.xpath("marc:datafield[@tag = ' ']/marc:subfield[@code = ' ']", namespaces=ns)
    try:
        GND = GND[0].text
    except:
        GND = "unknown"   

    meta_dict = {"author":author,
                 "titel":titel,
                 "GND":GND}
    
    return meta_dict

#diese funktion importiert eine liste von namen aus einer .csv-datei
#im gleichen ordner und gibt sie als list aus
#format: vorname nachname,
def import_persons():
    file = open("persons_list.csv", "r", encoding="utf-8")
    persons = list(csv.reader(file, delimiter=","))
    file.close()
    return persons

persons = import_persons()
#Leerer DataFrame wird vor Loop initiiert
df = pd.DataFrame()  
#Loopt durch die Namensliste und sucht jeweils gezielt nach Person,
#dann werden die Ergebnisse dem Dataframe hinzugefügt
for person in persons:
    records = dnb_sru('per=' + str(person))
    print(len(records), 'Ergebnisse')
    output = [parse_record(record) for record in records]
    df = df.append(output, ignore_index=True)

#Dataframe wird als .csv im gleichen Ordner gespeichert
df.to_csv("persons_list.csv", index=False)
